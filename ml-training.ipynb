{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"deepnote_notebook_id":"c3dab62c3b1140878c5e4edbec3a8d68","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10060611,"sourceType":"datasetVersion","datasetId":6199768},{"sourceId":10068168,"sourceType":"datasetVersion","datasetId":6205294},{"sourceId":10319215,"sourceType":"datasetVersion","datasetId":6207375},{"sourceId":10319537,"sourceType":"datasetVersion","datasetId":6389051},{"sourceId":10378686,"sourceType":"datasetVersion","datasetId":6429115}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport pickle as pk","metadata":{"source_hash":"152194d2","execution_start":1732532634663,"execution_millis":0,"execution_context_id":"a0fba925-838f-4a85-a700-5a37ae6506ee","cell_id":"935ebfec4d55450eb74b23dbc2038314","deepnote_cell_type":"code","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:24:15.078523Z","iopub.execute_input":"2025-01-08T20:24:15.078778Z","iopub.status.idle":"2025-01-08T20:24:16.956081Z","shell.execute_reply.started":"2025-01-08T20:24:15.078751Z","shell.execute_reply":"2025-01-08T20:24:16.955156Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install transformers","metadata":{"source_hash":"81ab85d2","execution_start":1732533531081,"execution_millis":11604,"execution_context_id":"a0fba925-838f-4a85-a700-5a37ae6506ee","cell_id":"4e932e3976794edbac52e4fc6786f42a","deepnote_cell_type":"code","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:27:18.310848Z","iopub.execute_input":"2025-01-08T20:27:18.311482Z","iopub.status.idle":"2025-01-08T20:28:00.940519Z","shell.execute_reply.started":"2025-01-08T20:27:18.311449Z","shell.execute_reply":"2025-01-08T20:28:00.939607Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nfrom transformers import RobertaTokenizer, TFRobertaModel\n\ndf = pd.read_csv('/kaggle/input/combined-df-csv/combined_df.csv')\n\ntokenizer = RobertaTokenizer.from_pretrained('/kaggle/input/codesynapsedataset/new_codebert_tokenizer/new_codebert_tokenizer')\nmodel = TFRobertaModel.from_pretrained('/kaggle/input/codesynapsedataset/new_codebert_model/new_codebert_model')\n\ndef generate_embeddings(code_list):\n    embeddings = []\n    for snippet in code_list:\n        inputs = tokenizer(snippet, return_tensors=\"tf\", padding=\"max_length\", truncation=True, max_length=512)\n        outputs = model(**inputs)\n        embedding = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n        embeddings.append(embedding.numpy())  \n    return embeddings  \n\nif 'original_code' not in df.columns or 'java_translation' not in df.columns:\n    raise ValueError(\"Ensure 'original_code' and 'java_translation' columns exist in the dataset!\")\n\noriginal_code_embeddings = generate_embeddings(df['original_code'].tolist())\njava_code_embeddings = generate_embeddings(df['java_translation'].tolist())\n\ndf['original_code_embeddings'] = [embedding.flatten().tolist() for embedding in original_code_embeddings]\ndf['java_code_embeddings'] = [embedding.flatten().tolist() for embedding in java_code_embeddings]\n\nembedding_size = len(original_code_embeddings[0]) \nfor i in range(embedding_size):\n    df[f'original_code_emb_{i}'] = [embedding[i] for embedding in original_code_embeddings]\n    df[f'java_code_emb_{i}'] = [embedding[i] for embedding in java_code_embeddings]\n\ndf.drop(columns=['original_code_embeddings', 'java_code_embeddings'], inplace=True)\n\noutput_directory = \"./data\" \n\nos.makedirs(output_directory, exist_ok=True)\n\ncsv_path = os.path.join(output_directory, \"code_embeddings_flat1.csv\")\npkl_path = os.path.join(output_directory, \"code_embeddings_flat1.pkl\")\n\ndf.to_csv(csv_path, index=False) \ndf.to_pickle(pkl_path)  \n\nprint(f\"Embeddings generated, flattened, and saved to {csv_path} and {pkl_path}!\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:34:00.878733Z","iopub.execute_input":"2025-01-08T20:34:00.879436Z","iopub.status.idle":"2025-01-08T20:37:41.163507Z","shell.execute_reply.started":"2025-01-08T20:34:00.879399Z","shell.execute_reply":"2025-01-08T20:37:41.162594Z"}},"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFRobertaModel.\n\nAll the weights of TFRobertaModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Embeddings generated, flattened, and saved to ./data/code_embeddings_flat1.csv and ./data/code_embeddings_flat1.pkl!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Bidirectional\nimport re\n\ndef fix_array_format(array_str):\n    array_str = re.sub(r'(?<=\\d)\\s+(?=\\d)', ', ', array_str)\n    return np.array(eval(array_str))\n\nfile_path = './data/code_embeddings_flat1.csv'\ndf = pd.read_csv(file_path)\n\noriginal_embeddings = df['original_code_emb_0'].apply(fix_array_format)\njava_embeddings = df['java_code_emb_0'].apply(fix_array_format)\nlabels = df['Is_Equal'].values\n\nmax_seq_length = max(original_embeddings.apply(len).max(), java_embeddings.apply(len).max())\noriginal_embeddings = pad_sequences(original_embeddings, maxlen=max_seq_length, dtype='float32', padding='post', truncating='post')\njava_embeddings = pad_sequences(java_embeddings, maxlen=max_seq_length, dtype='float32', padding='post', truncating='post')\n\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(labels)\n\noriginal_embeddings = original_embeddings.reshape(original_embeddings.shape[0], original_embeddings.shape[1], 1)\njava_embeddings = java_embeddings.reshape(java_embeddings.shape[0], java_embeddings.shape[1], 1)\n\nX_train_orig, X_test_orig, X_train_java, X_test_java, y_train, y_test = train_test_split(\n    original_embeddings, java_embeddings, labels, test_size=0.2, random_state=42\n)\n\n\nlstm_layer = Bidirectional(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3), name='shared_bidirectional_lstm')\n\ninput_original = Input(shape=(original_embeddings.shape[1], 1), name='original_input')\ninput_java = Input(shape=(java_embeddings.shape[1], 1), name='java_input')\n\nencoded_original = lstm_layer(input_original)\nencoded_java = lstm_layer(input_java)\n\ncombined = Concatenate()([encoded_original, encoded_java])\n\ndense = Dense(64, activation='relu')(combined)\ndropout = Dropout(0.3)(dense)\noutput = Dense(1, activation='sigmoid')(dropout)\n\nmodel = Model(inputs=[input_original, input_java], outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    [X_train_orig, X_train_java], y_train,\n    validation_data=([X_test_orig, X_test_java], y_test),\n    epochs=30,\n    batch_size=64,\n    verbose=2,\n    callbacks=[early_stopping]\n)\n\ntrain_loss, train_accuracy = model.evaluate([X_train_orig, X_train_java], y_train, verbose=2)\ntest_loss, test_accuracy = model.evaluate([X_test_orig, X_test_java], y_test, verbose=2)\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")\nprint(f\"Testing Accuracy: {test_accuracy:.4f}\")\n\nmodel.save('lstm_model.h5')\n\npython_embedding_model = Model(inputs=input_original, outputs=encoded_original)\npython_refined_embeddings = python_embedding_model.predict(original_embeddings)\n\njava_embedding_model = Model(inputs=input_java, outputs=encoded_java)\njava_refined_embeddings = java_embedding_model.predict(java_embeddings)\n\nrefined_embeddings_df = pd.DataFrame({\n    'Python_Refined': list(python_refined_embeddings),\n    'Java_Refined': list(java_refined_embeddings),\n    'Is_Equal': labels\n})\n\nrefined_embeddings_df.to_csv('refined_embeddings_with_labels.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:37:56.452670Z","iopub.execute_input":"2025-01-08T20:37:56.453005Z","iopub.status.idle":"2025-01-08T20:39:10.413572Z","shell.execute_reply.started":"2025-01-08T20:37:56.452975Z","shell.execute_reply":"2025-01-08T20:39:10.412824Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n6/6 - 12s - 2s/step - accuracy: 0.4714 - loss: 0.6934 - val_accuracy: 0.5208 - val_loss: 0.6929\nEpoch 2/30\n6/6 - 5s - 846ms/step - accuracy: 0.5026 - loss: 0.6933 - val_accuracy: 0.5208 - val_loss: 0.6925\nEpoch 3/30\n6/6 - 5s - 836ms/step - accuracy: 0.5208 - loss: 0.6920 - val_accuracy: 0.5208 - val_loss: 0.6925\nEpoch 4/30\n6/6 - 5s - 840ms/step - accuracy: 0.5286 - loss: 0.6918 - val_accuracy: 0.5208 - val_loss: 0.6925\nEpoch 5/30\n6/6 - 5s - 830ms/step - accuracy: 0.5078 - loss: 0.6944 - val_accuracy: 0.5208 - val_loss: 0.6929\nEpoch 6/30\n6/6 - 5s - 871ms/step - accuracy: 0.5286 - loss: 0.6915 - val_accuracy: 0.5208 - val_loss: 0.6926\nEpoch 7/30\n6/6 - 5s - 844ms/step - accuracy: 0.5234 - loss: 0.6915 - val_accuracy: 0.5208 - val_loss: 0.6924\nEpoch 8/30\n6/6 - 5s - 840ms/step - accuracy: 0.5208 - loss: 0.6917 - val_accuracy: 0.5208 - val_loss: 0.6925\nEpoch 9/30\n6/6 - 6s - 927ms/step - accuracy: 0.5078 - loss: 0.6929 - val_accuracy: 0.5208 - val_loss: 0.6925\nEpoch 10/30\n6/6 - 5s - 835ms/step - accuracy: 0.5339 - loss: 0.6913 - val_accuracy: 0.5312 - val_loss: 0.6926\n12/12 - 4s - 338ms/step - accuracy: 0.5208 - loss: 0.6913\n3/3 - 1s - 348ms/step - accuracy: 0.5208 - loss: 0.6924\nTraining Accuracy: 0.5208\nTesting Accuracy: 0.5208\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport ast\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Lambda\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n\nlstm_output_file = 'refined_embeddings_with_labels.csv'\nlstm_embeddings_df = pd.read_csv(lstm_output_file)\n\ndef parse_embeddings(embedding_str):\n    try:\n        return np.array(ast.literal_eval(embedding_str))\n    except (ValueError, SyntaxError):\n        return np.array([])\n\npy_embeddings = lstm_embeddings_df['Python_Refined'].apply(parse_embeddings)\njava_embeddings = lstm_embeddings_df['Java_Refined'].apply(parse_embeddings)\n\nembedding_length = py_embeddings.iloc[0].shape[0] \npy_embeddings = np.array([emb if emb.shape[0] == embedding_length else np.zeros(embedding_length) for emb in py_embeddings])\njava_embeddings = np.array([emb if emb.shape[0] == embedding_length else np.zeros(embedding_length) for emb in java_embeddings])\n\ndef create_simplified_siamese_network(input_dim):\n    input_a = Input(shape=(input_dim,))\n    input_b = Input(shape=(input_dim,))\n    \n    l1_distance = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))\n    l1_dist = l1_distance([input_a, input_b])\n    \n    output = Dense(1, activation='sigmoid')(l1_dist)\n\n    siamese_model = Model(inputs=[input_a, input_b], outputs=output)\n    siamese_model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return siamese_model\n\ninput_dim = py_embeddings.shape[1]\nsiamese_model = create_simplified_siamese_network(input_dim)\n\nsimilarity_scores = siamese_model.predict([py_embeddings, java_embeddings], verbose=0).flatten()\n\n\nsimilarity_df = pd.DataFrame({\n    'Python_Refined': lstm_embeddings_df['Python_Refined'],\n    'Java_Refined': lstm_embeddings_df['Java_Refined'],\n    'Is_Equal': lstm_embeddings_df['Is_Equal'],\n    'Similarity_Score': similarity_scores\n})\nsimilarity_df.to_csv('siamese_similarity_scores.csv', index=False)\n\nprint(\"Similarity calculations completed. Results saved to siamese_similarity_scores.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:39:20.163566Z","iopub.execute_input":"2025-01-08T20:39:20.164464Z","iopub.status.idle":"2025-01-08T20:39:20.480041Z","shell.execute_reply.started":"2025-01-08T20:39:20.164430Z","shell.execute_reply":"2025-01-08T20:39:20.478930Z"}},"outputs":[{"name":"stdout","text":"Similarity calculations completed. Results saved to siamese_similarity_scores.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\ndf = pd.read_csv('siamese_similarity_scores.csv')\n\nfeatures = df['Similarity_Score'].values.reshape(-1, 1)\n\nlabels = df['Is_Equal'].values\n\nprint(f\"Features shape: {features.shape}\")  \nprint(f\"Labels shape: {labels.shape}\")      \n\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n\ndef build_fcnn():\n    model = Sequential([\n        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dropout(0.2),\n        Dense(1, activation='sigmoid')  # Binary classification output\n    ])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\nfcnn_model = build_fcnn()\n\nepochs = 30\nbatch_size = 16\n\nhistory = fcnn_model.fit(\n    X_train, y_train,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_split=0.2,\n    verbose=1\n)\n\ny_pred = fcnn_model.predict(X_test).flatten()\ny_pred_binary = (y_pred > 0.5).astype(int)  \n\ntest_accuracy = accuracy_score(y_test, y_pred_binary)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\ny_train_pred = fcnn_model.predict(X_train).flatten()\ny_train_pred_binary = (y_train_pred > 0.5).astype(int)\n\ntrain_accuracy = accuracy_score(y_train, y_train_pred_binary)\nprint(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n\nfcnn_model.save('fcnn_model.h5')\n\npredictions_df = pd.DataFrame({\n    'True_Label': y_test,\n    'Predicted_Probability': y_pred,\n    'Predicted_Label': y_pred_binary\n})\npredictions_df.to_csv('fcnn_predictions.csv', index=False)\n\nprint(\"FCNN model and predictions saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:39:42.289088Z","iopub.execute_input":"2025-01-08T20:39:42.289404Z","iopub.status.idle":"2025-01-08T20:39:50.475144Z","shell.execute_reply.started":"2025-01-08T20:39:42.289361Z","shell.execute_reply":"2025-01-08T20:39:50.474098Z"}},"outputs":[{"name":"stdout","text":"Features shape: (480, 1)\nLabels shape: (480,)\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - accuracy: 0.5814 - loss: 0.6841 - val_accuracy: 0.4559 - val_loss: 0.7058\nEpoch 2/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5420 - loss: 0.6924 - val_accuracy: 0.4559 - val_loss: 0.7017\nEpoch 3/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 0.6915 - val_accuracy: 0.4559 - val_loss: 0.7014\nEpoch 4/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 0.6903 - val_accuracy: 0.4559 - val_loss: 0.7020\nEpoch 5/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5385 - loss: 0.6911 - val_accuracy: 0.4559 - val_loss: 0.7013\nEpoch 6/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5283 - loss: 0.6978 - val_accuracy: 0.4559 - val_loss: 0.7028\nEpoch 7/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5164 - loss: 0.6935 - val_accuracy: 0.4559 - val_loss: 0.7026\nEpoch 8/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4969 - loss: 0.6959 - val_accuracy: 0.4559 - val_loss: 0.7012\nEpoch 9/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6826 - val_accuracy: 0.4559 - val_loss: 0.7040\nEpoch 10/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5178 - loss: 0.6964 - val_accuracy: 0.4559 - val_loss: 0.7025\nEpoch 11/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5488 - loss: 0.6900 - val_accuracy: 0.4559 - val_loss: 0.7040\nEpoch 12/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5084 - loss: 0.6977 - val_accuracy: 0.4559 - val_loss: 0.7005\nEpoch 13/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5524 - loss: 0.6854 - val_accuracy: 0.4559 - val_loss: 0.7022\nEpoch 14/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 0.6857 - val_accuracy: 0.4559 - val_loss: 0.7036\nEpoch 15/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 0.6894 - val_accuracy: 0.4559 - val_loss: 0.7021\nEpoch 16/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5489 - loss: 0.6916 - val_accuracy: 0.4559 - val_loss: 0.7022\nEpoch 17/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5189 - loss: 0.6933 - val_accuracy: 0.4559 - val_loss: 0.7012\nEpoch 18/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5413 - loss: 0.6912 - val_accuracy: 0.4559 - val_loss: 0.7029\nEpoch 19/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5264 - loss: 0.6951 - val_accuracy: 0.4559 - val_loss: 0.7025\nEpoch 20/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4899 - loss: 0.7046 - val_accuracy: 0.4559 - val_loss: 0.7009\nEpoch 21/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5034 - loss: 0.6964 - val_accuracy: 0.4559 - val_loss: 0.6999\nEpoch 22/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5680 - loss: 0.6858 - val_accuracy: 0.4559 - val_loss: 0.7029\nEpoch 23/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5563 - loss: 0.6859 - val_accuracy: 0.4559 - val_loss: 0.7052\nEpoch 24/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 0.6861 - val_accuracy: 0.4559 - val_loss: 0.7028\nEpoch 25/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5360 - loss: 0.6868 - val_accuracy: 0.4559 - val_loss: 0.7038\nEpoch 26/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5728 - loss: 0.6841 - val_accuracy: 0.4559 - val_loss: 0.7039\nEpoch 27/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5156 - loss: 0.6930 - val_accuracy: 0.4559 - val_loss: 0.7037\nEpoch 28/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 0.6914 - val_accuracy: 0.4559 - val_loss: 0.7046\nEpoch 29/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 0.6797 - val_accuracy: 0.4559 - val_loss: 0.7064\nEpoch 30/30\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: 0.6971 - val_accuracy: 0.4559 - val_loss: 0.7008\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\nTest Accuracy: 51.39%\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \nTrain Accuracy: 52.38%\nFCNN model and predictions saved.\n","output_type":"stream"}],"execution_count":9}]}